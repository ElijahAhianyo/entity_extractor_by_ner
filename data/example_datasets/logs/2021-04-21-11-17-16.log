2021-04-21 11:17:16
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY++++++++++++++++++++++++++++++++++++++++
 Status:
     mode                 : train
 ++++++++++++++++++++++++++++++++++++++++
 Datasets:
     datasets         fold: data/example_datasets
     train            file: train.csv
     validation       file: dev.csv
     vocab             dir: data/example_datasets/vocabs
     delimiter            : b
     use              bert: False
     checkpoints       dir: checkpoints/datasets_bilsm-crf
     log               dir: data/example_datasets/logs
 ++++++++++++++++++++++++++++++++++++++++
Labeling Scheme:
     label          scheme: BIO
     label           level: 2
     suffixes             : ['ORG', 'PER', 'LOC']
     measuring     metrics: ['precision', 'recall', 'f1', 'accuracy']
 ++++++++++++++++++++++++++++++++++++++++
Model Configuration:
     embedding         dim: 300
     max  sequence  length: 300
     hidden            dim: 200
     CUDA  VISIBLE  DEVICE: 0
     seed                 : 42
 ++++++++++++++++++++++++++++++++++++++++
 Training Settings:
     epoch                : 300
     batch            size: 32
     dropout              : 0.5
     learning         rate: 0.001
     optimizer            : Adam
     checkpoint       name: model
     max       checkpoints: 1
     print       per_batch: 20
     is     early     stop: True
     patient              : 5
++++++++++++++++++++++++++++++++++++++++CONFIGURATION SUMMARY END++++++++++++++++++++++++++++++++++++++++
loading vocab...
dataManager initialed...
mode: train
loading data...
loading data...
training set size: 23181, validating set size: 4636
++++++++++++++++++++training starting++++++++++++++++++++
epoch:1/300
training batch:    20, loss: 32.59656, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.874 
training batch:    40, loss: 30.16566, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.888 
training batch:    60, loss: 19.53192, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.904 
training batch:    80, loss: 19.11486, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.880 
training batch:   100, loss: 20.74996, precision: -1.000 recall: 0.000 f1: -1.000 accuracy: 0.880 
training batch:   120, loss: 14.40720, precision: 0.000 recall: 0.000 f1: -1.000 accuracy: 0.897 
training batch:   140, loss: 11.30134, precision: 0.273 recall: 0.068 f1: 0.109 accuracy: 0.915 
training batch:   160, loss: 14.94350, precision: 0.222 recall: 0.095 f1: 0.133 accuracy: 0.904 
training batch:   180, loss: 14.80433, precision: 0.333 recall: 0.186 f1: 0.239 accuracy: 0.886 
training batch:   200, loss: 13.91296, precision: 0.311 recall: 0.246 f1: 0.275 accuracy: 0.920 
training batch:   220, loss: 10.70325, precision: 0.333 recall: 0.209 f1: 0.257 accuracy: 0.916 
training batch:   240, loss: 8.47161, precision: 0.464 recall: 0.255 f1: 0.329 accuracy: 0.931 
training batch:   260, loss: 8.20465, precision: 0.300 recall: 0.237 f1: 0.265 accuracy: 0.937 
training batch:   280, loss: 9.66355, precision: 0.409 recall: 0.353 f1: 0.379 accuracy: 0.897 
training batch:   300, loss: 5.43142, precision: 0.476 recall: 0.312 f1: 0.377 accuracy: 0.957 
training batch:   320, loss: 9.15520, precision: 0.600 recall: 0.375 f1: 0.462 accuracy: 0.937 
training batch:   340, loss: 7.26662, precision: 0.533 recall: 0.522 f1: 0.527 accuracy: 0.937 
training batch:   360, loss: 8.04836, precision: 0.531 recall: 0.491 f1: 0.510 accuracy: 0.935 
training batch:   380, loss: 10.37452, precision: 0.520 recall: 0.394 f1: 0.448 accuracy: 0.918 
training batch:   400, loss: 10.51965, precision: 0.512 recall: 0.356 f1: 0.420 accuracy: 0.900 
training batch:   420, loss: 8.18311, precision: 0.571 recall: 0.491 f1: 0.528 accuracy: 0.938 
training batch:   440, loss: 8.52345, precision: 0.568 recall: 0.472 f1: 0.515 accuracy: 0.949 
training batch:   460, loss: 9.28482, precision: 0.612 recall: 0.492 f1: 0.545 accuracy: 0.914 
training batch:   480, loss: 6.70758, precision: 0.617 recall: 0.527 f1: 0.569 accuracy: 0.947 
training batch:   500, loss: 7.89467, precision: 0.667 recall: 0.609 f1: 0.636 accuracy: 0.954 
training batch:   520, loss: 8.53284, precision: 0.550 recall: 0.559 f1: 0.555 accuracy: 0.940 
training batch:   540, loss: 7.59103, precision: 0.612 recall: 0.556 f1: 0.583 accuracy: 0.940 
training batch:   560, loss: 7.36386, precision: 0.562 recall: 0.659 f1: 0.607 accuracy: 0.936 
training batch:   580, loss: 7.54231, precision: 0.662 recall: 0.623 f1: 0.642 accuracy: 0.945 
training batch:   600, loss: 6.05944, precision: 0.610 recall: 0.568 f1: 0.588 accuracy: 0.963 
training batch:   620, loss: 4.40640, precision: 0.568 recall: 0.500 f1: 0.532 accuracy: 0.954 
training batch:   640, loss: 5.68848, precision: 0.698 recall: 0.536 f1: 0.606 accuracy: 0.952 
training batch:   660, loss: 5.54244, precision: 0.588 recall: 0.571 f1: 0.580 accuracy: 0.952 
training batch:   680, loss: 5.45025, precision: 0.560 recall: 0.500 f1: 0.528 accuracy: 0.948 
training batch:   700, loss: 6.89599, precision: 0.651 recall: 0.549 f1: 0.596 accuracy: 0.959 
training batch:   720, loss: 3.96383, precision: 0.611 recall: 0.564 f1: 0.587 accuracy: 0.963 
start evaluate engines...
label: ORG, precision: 0.521 recall: 0.436 f1: 0.460 accuracy: 0.000 
label: PER, precision: 0.737 recall: 0.559 f1: 0.622 accuracy: 0.000 
label: LOC, precision: 0.555 recall: 0.582 f1: 0.559 accuracy: 0.000 
time consumption:8.69(min), precision: 0.631 recall: 0.570 f1: 0.596 accuracy: 0.957 
saved the new best model with f1: 0.596
epoch:2/300
training batch:    20, loss: 7.66482, precision: 0.646 recall: 0.646 f1: 0.646 accuracy: 0.954 
training batch:    40, loss: 5.06429, precision: 0.595 recall: 0.472 f1: 0.526 accuracy: 0.957 
training batch:    60, loss: 4.18096, precision: 0.636 recall: 0.596 f1: 0.615 accuracy: 0.965 
training batch:    80, loss: 3.99301, precision: 0.676 recall: 0.511 f1: 0.582 accuracy: 0.951 
training batch:   100, loss: 6.37667, precision: 0.814 recall: 0.700 f1: 0.753 accuracy: 0.955 
training batch:   120, loss: 3.98700, precision: 0.564 recall: 0.585 f1: 0.574 accuracy: 0.962 
training batch:   140, loss: 4.16442, precision: 0.610 recall: 0.568 f1: 0.588 accuracy: 0.965 
training batch:   160, loss: 4.12230, precision: 0.636 recall: 0.600 f1: 0.618 accuracy: 0.967 
training batch:   180, loss: 5.43745, precision: 0.704 recall: 0.633 f1: 0.667 accuracy: 0.955 
training batch:   200, loss: 4.56432, precision: 0.562 recall: 0.419 f1: 0.480 accuracy: 0.953 
training batch:   220, loss: 4.53730, precision: 0.633 recall: 0.528 f1: 0.576 accuracy: 0.962 
training batch:   240, loss: 4.42341, precision: 0.711 recall: 0.659 f1: 0.684 accuracy: 0.945 
training batch:   260, loss: 4.15087, precision: 0.878 recall: 0.692 f1: 0.774 accuracy: 0.960 
training batch:   280, loss: 3.98040, precision: 0.667 recall: 0.619 f1: 0.642 accuracy: 0.956 
training batch:   300, loss: 3.21206, precision: 0.621 recall: 0.643 f1: 0.632 accuracy: 0.972 
training batch:   320, loss: 4.43347, precision: 0.606 recall: 0.571 f1: 0.588 accuracy: 0.957 
training batch:   340, loss: 3.74970, precision: 0.676 recall: 0.625 f1: 0.649 accuracy: 0.970 
training batch:   360, loss: 4.16377, precision: 0.682 recall: 0.652 f1: 0.667 accuracy: 0.944 
training batch:   380, loss: 3.94003, precision: 0.750 recall: 0.765 f1: 0.757 accuracy: 0.969 
training batch:   400, loss: 7.11072, precision: 0.719 recall: 0.641 f1: 0.678 accuracy: 0.938 
training batch:   420, loss: 3.04082, precision: 0.657 recall: 0.676 f1: 0.667 accuracy: 0.969 
training batch:   440, loss: 3.77132, precision: 0.949 recall: 0.787 f1: 0.860 accuracy: 0.968 
training batch:   460, loss: 2.78407, precision: 0.714 recall: 0.714 f1: 0.714 accuracy: 0.977 
training batch:   480, loss: 4.86442, precision: 0.723 recall: 0.596 f1: 0.654 accuracy: 0.950 
training batch:   500, loss: 3.45606, precision: 0.594 recall: 0.576 f1: 0.585 accuracy: 0.964 
training batch:   520, loss: 4.17310, precision: 0.780 recall: 0.754 f1: 0.767 accuracy: 0.965 
training batch:   540, loss: 2.86270, precision: 0.694 recall: 0.658 f1: 0.676 accuracy: 0.970 
training batch:   560, loss: 4.17979, precision: 0.736 recall: 0.696 f1: 0.716 accuracy: 0.963 
training batch:   580, loss: 4.21332, precision: 0.587 recall: 0.509 f1: 0.545 accuracy: 0.952 
training batch:   600, loss: 5.46400, precision: 0.704 recall: 0.750 f1: 0.726 accuracy: 0.945 
training batch:   620, loss: 3.56382, precision: 0.788 recall: 0.684 f1: 0.732 accuracy: 0.964 
training batch:   640, loss: 5.17631, precision: 0.738 recall: 0.608 f1: 0.667 accuracy: 0.965 
training batch:   660, loss: 3.89121, precision: 0.723 recall: 0.576 f1: 0.642 accuracy: 0.963 
training batch:   680, loss: 2.74099, precision: 0.707 recall: 0.630 f1: 0.667 accuracy: 0.973 
training batch:   700, loss: 2.60863, precision: 0.833 recall: 0.714 f1: 0.769 accuracy: 0.976 
training batch:   720, loss: 3.34233, precision: 0.800 recall: 0.769 f1: 0.784 accuracy: 0.962 
start evaluate engines...
label: ORG, precision: 0.587 recall: 0.640 f1: 0.600 accuracy: 0.000 
label: PER, precision: 0.802 recall: 0.768 f1: 0.776 accuracy: 0.000 
label: LOC, precision: 0.716 recall: 0.685 f1: 0.693 accuracy: 0.000 
time consumption:8.43(min), precision: 0.727 recall: 0.712 f1: 0.718 accuracy: 0.966 
saved the new best model with f1: 0.718
epoch:3/300
training batch:    20, loss: 6.23823, precision: 0.667 recall: 0.658 f1: 0.662 accuracy: 0.945 
training batch:    40, loss: 1.70349, precision: 0.829 recall: 0.810 f1: 0.819 accuracy: 0.986 
training batch:    60, loss: 3.15277, precision: 0.746 recall: 0.721 f1: 0.733 accuracy: 0.977 
training batch:    80, loss: 3.76402, precision: 0.836 recall: 0.793 f1: 0.814 accuracy: 0.968 
training batch:   100, loss: 3.42527, precision: 0.744 recall: 0.615 f1: 0.674 accuracy: 0.963 
training batch:   120, loss: 2.97467, precision: 0.778 recall: 0.673 f1: 0.722 accuracy: 0.967 
training batch:   140, loss: 1.99134, precision: 0.712 recall: 0.804 f1: 0.755 accuracy: 0.985 
training batch:   160, loss: 1.90085, precision: 0.833 recall: 0.735 f1: 0.781 accuracy: 0.976 
training batch:   180, loss: 3.03230, precision: 0.828 recall: 0.800 f1: 0.814 accuracy: 0.975 
training batch:   200, loss: 3.84597, precision: 0.742 recall: 0.708 f1: 0.724 accuracy: 0.961 
training batch:   220, loss: 3.01660, precision: 0.767 recall: 0.793 f1: 0.780 accuracy: 0.959 
training batch:   240, loss: 2.92167, precision: 0.730 recall: 0.692 f1: 0.711 accuracy: 0.972 
training batch:   260, loss: 4.20243, precision: 0.797 recall: 0.734 f1: 0.764 accuracy: 0.967 
training batch:   280, loss: 2.57314, precision: 0.811 recall: 0.754 f1: 0.782 accuracy: 0.969 
training batch:   300, loss: 3.17332, precision: 0.579 recall: 0.579 f1: 0.579 accuracy: 0.961 
training batch:   320, loss: 3.16493, precision: 0.730 recall: 0.643 f1: 0.684 accuracy: 0.962 
training batch:   340, loss: 4.33706, precision: 0.808 recall: 0.712 f1: 0.757 accuracy: 0.961 
training batch:   360, loss: 2.83205, precision: 0.762 recall: 0.774 f1: 0.768 accuracy: 0.968 
training batch:   380, loss: 2.22484, precision: 0.800 recall: 0.870 f1: 0.833 accuracy: 0.974 
training batch:   400, loss: 3.52585, precision: 0.922 recall: 0.758 f1: 0.832 accuracy: 0.966 
training batch:   420, loss: 3.02077, precision: 0.844 recall: 0.655 f1: 0.738 accuracy: 0.972 
training batch:   440, loss: 2.03888, precision: 0.857 recall: 0.766 f1: 0.809 accuracy: 0.981 
training batch:   460, loss: 2.78106, precision: 0.826 recall: 0.776 f1: 0.800 accuracy: 0.965 
training batch:   480, loss: 2.82622, precision: 0.812 recall: 0.823 f1: 0.818 accuracy: 0.972 
training batch:   500, loss: 3.57445, precision: 0.700 recall: 0.673 f1: 0.686 accuracy: 0.964 
training batch:   520, loss: 2.53894, precision: 0.667 recall: 0.714 f1: 0.690 accuracy: 0.975 
training batch:   540, loss: 2.18100, precision: 0.781 recall: 0.676 f1: 0.725 accuracy: 0.972 
training batch:   560, loss: 1.81287, precision: 0.893 recall: 0.781 f1: 0.833 accuracy: 0.975 
training batch:   580, loss: 1.84311, precision: 0.867 recall: 0.796 f1: 0.830 accuracy: 0.983 
training batch:   600, loss: 1.87026, precision: 0.814 recall: 0.814 f1: 0.814 accuracy: 0.983 
training batch:   620, loss: 2.45669, precision: 0.960 recall: 0.706 f1: 0.814 accuracy: 0.976 
training batch:   640, loss: 3.24541, precision: 0.785 recall: 0.761 f1: 0.773 accuracy: 0.969 
training batch:   660, loss: 2.31730, precision: 0.864 recall: 0.776 f1: 0.817 accuracy: 0.983 
training batch:   680, loss: 2.59725, precision: 0.750 recall: 0.805 f1: 0.776 accuracy: 0.966 
training batch:   700, loss: 1.05342, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.994 
training batch:   720, loss: 3.62652, precision: 0.804 recall: 0.732 f1: 0.766 accuracy: 0.950 
start evaluate engines...
label: ORG, precision: 0.746 recall: 0.601 f1: 0.654 accuracy: 0.000 
label: PER, precision: 0.866 recall: 0.789 f1: 0.818 accuracy: 0.000 
label: LOC, precision: 0.752 recall: 0.802 f1: 0.769 accuracy: 0.000 
time consumption:8.37(min), precision: 0.814 recall: 0.764 f1: 0.786 accuracy: 0.972 
saved the new best model with f1: 0.786
epoch:4/300
training batch:    20, loss: 3.32893, precision: 0.763 recall: 0.763 f1: 0.763 accuracy: 0.960 
training batch:    40, loss: 2.51962, precision: 0.796 recall: 0.754 f1: 0.775 accuracy: 0.978 
training batch:    60, loss: 2.49039, precision: 0.750 recall: 0.700 f1: 0.724 accuracy: 0.969 
training batch:    80, loss: 1.61877, precision: 0.805 recall: 0.805 f1: 0.805 accuracy: 0.981 
training batch:   100, loss: 0.79940, precision: 0.821 recall: 0.920 f1: 0.868 accuracy: 0.988 
training batch:   120, loss: 1.96159, precision: 0.877 recall: 0.806 f1: 0.840 accuracy: 0.978 
training batch:   140, loss: 1.97501, precision: 0.938 recall: 0.909 f1: 0.923 accuracy: 0.990 
training batch:   160, loss: 2.58815, precision: 0.860 recall: 0.841 f1: 0.851 accuracy: 0.978 
training batch:   180, loss: 1.88122, precision: 0.771 recall: 0.771 f1: 0.771 accuracy: 0.978 
training batch:   200, loss: 1.52538, precision: 0.889 recall: 0.923 f1: 0.906 accuracy: 0.982 
training batch:   220, loss: 3.20445, precision: 0.915 recall: 0.754 f1: 0.827 accuracy: 0.946 
training batch:   240, loss: 1.65172, precision: 0.872 recall: 0.837 f1: 0.854 accuracy: 0.984 
training batch:   260, loss: 1.84862, precision: 0.786 recall: 0.710 f1: 0.746 accuracy: 0.970 
training batch:   280, loss: 1.25564, precision: 0.915 recall: 0.860 f1: 0.887 accuracy: 0.984 
training batch:   300, loss: 1.66294, precision: 0.878 recall: 0.837 f1: 0.857 accuracy: 0.974 
training batch:   320, loss: 2.22678, precision: 0.879 recall: 0.853 f1: 0.866 accuracy: 0.969 
training batch:   340, loss: 1.80571, precision: 0.864 recall: 0.905 f1: 0.884 accuracy: 0.968 
training batch:   360, loss: 1.76479, precision: 0.811 recall: 0.833 f1: 0.822 accuracy: 0.983 
training batch:   380, loss: 2.24958, precision: 0.887 recall: 0.825 f1: 0.855 accuracy: 0.977 
training batch:   400, loss: 2.34982, precision: 0.885 recall: 0.852 f1: 0.868 accuracy: 0.981 
training batch:   420, loss: 1.84682, precision: 0.806 recall: 0.758 f1: 0.781 accuracy: 0.980 
training batch:   440, loss: 2.14633, precision: 0.773 recall: 0.723 f1: 0.747 accuracy: 0.961 
training batch:   460, loss: 1.77311, precision: 0.829 recall: 0.784 f1: 0.806 accuracy: 0.982 
training batch:   480, loss: 1.54684, precision: 0.872 recall: 0.850 f1: 0.861 accuracy: 0.979 
training batch:   500, loss: 2.12579, precision: 0.935 recall: 0.878 f1: 0.905 accuracy: 0.978 
training batch:   520, loss: 2.47207, precision: 0.778 recall: 0.729 f1: 0.753 accuracy: 0.967 
training batch:   540, loss: 1.51592, precision: 0.897 recall: 0.788 f1: 0.839 accuracy: 0.988 
training batch:   560, loss: 1.20265, precision: 0.902 recall: 0.841 f1: 0.871 accuracy: 0.975 
training batch:   580, loss: 2.02905, precision: 0.887 recall: 0.797 f1: 0.839 accuracy: 0.979 
training batch:   600, loss: 2.34726, precision: 0.780 recall: 0.842 f1: 0.810 accuracy: 0.974 
training batch:   620, loss: 1.71684, precision: 0.788 recall: 0.854 f1: 0.820 accuracy: 0.975 
training batch:   640, loss: 2.22253, precision: 0.865 recall: 0.849 f1: 0.857 accuracy: 0.978 
training batch:   660, loss: 1.49919, precision: 0.912 recall: 0.838 f1: 0.873 accuracy: 0.986 
training batch:   680, loss: 1.64883, precision: 0.857 recall: 0.750 f1: 0.800 accuracy: 0.975 
training batch:   700, loss: 1.15483, precision: 0.829 recall: 0.879 f1: 0.853 accuracy: 0.990 
training batch:   720, loss: 1.12433, precision: 0.974 recall: 0.905 f1: 0.938 accuracy: 0.994 
start evaluate engines...
label: ORG, precision: 0.802 recall: 0.631 f1: 0.694 accuracy: 0.000 
label: PER, precision: 0.872 recall: 0.836 f1: 0.846 accuracy: 0.000 
label: LOC, precision: 0.787 recall: 0.809 f1: 0.791 accuracy: 0.000 
time consumption:8.29(min), precision: 0.846 recall: 0.785 f1: 0.813 accuracy: 0.975 
saved the new best model with f1: 0.813
epoch:5/300
training batch:    20, loss: 1.73526, precision: 0.896 recall: 0.878 f1: 0.887 accuracy: 0.978 
training batch:    40, loss: 1.62427, precision: 0.868 recall: 0.807 f1: 0.836 accuracy: 0.983 
training batch:    60, loss: 1.39382, precision: 0.902 recall: 0.841 f1: 0.871 accuracy: 0.984 
training batch:    80, loss: 1.63875, precision: 0.774 recall: 0.872 f1: 0.820 accuracy: 0.982 
training batch:   100, loss: 1.26299, precision: 0.886 recall: 0.867 f1: 0.876 accuracy: 0.981 
training batch:   120, loss: 0.62131, precision: 0.967 recall: 0.935 f1: 0.951 accuracy: 0.991 
training batch:   140, loss: 1.12566, precision: 0.911 recall: 0.854 f1: 0.882 accuracy: 0.984 
training batch:   160, loss: 1.36005, precision: 0.806 recall: 0.758 f1: 0.781 accuracy: 0.980 
training batch:   180, loss: 1.61590, precision: 0.964 recall: 0.855 f1: 0.906 accuracy: 0.986 
training batch:   200, loss: 1.35322, precision: 0.820 recall: 0.804 f1: 0.812 accuracy: 0.981 
training batch:   220, loss: 0.99296, precision: 0.919 recall: 0.872 f1: 0.895 accuracy: 0.985 
training batch:   240, loss: 2.15206, precision: 0.780 recall: 0.744 f1: 0.762 accuracy: 0.971 
training batch:   260, loss: 1.70850, precision: 0.893 recall: 0.758 f1: 0.820 accuracy: 0.980 
training batch:   280, loss: 1.45941, precision: 0.906 recall: 0.889 f1: 0.897 accuracy: 0.985 
training batch:   300, loss: 2.42537, precision: 0.816 recall: 0.721 f1: 0.765 accuracy: 0.982 
training batch:   320, loss: 2.04931, precision: 0.766 recall: 0.750 f1: 0.758 accuracy: 0.969 
training batch:   340, loss: 1.16433, precision: 0.905 recall: 0.950 f1: 0.927 accuracy: 0.988 
training batch:   360, loss: 1.11544, precision: 0.769 recall: 0.882 f1: 0.822 accuracy: 0.981 
training batch:   380, loss: 2.52033, precision: 0.810 recall: 0.723 f1: 0.764 accuracy: 0.973 
training batch:   400, loss: 0.77245, precision: 0.850 recall: 0.872 f1: 0.861 accuracy: 0.991 
training batch:   420, loss: 1.27490, precision: 0.818 recall: 0.844 f1: 0.831 accuracy: 0.983 
training batch:   440, loss: 0.73024, precision: 0.889 recall: 0.800 f1: 0.842 accuracy: 0.988 
training batch:   460, loss: 2.77170, precision: 0.927 recall: 0.785 f1: 0.850 accuracy: 0.975 
training batch:   480, loss: 1.81424, precision: 0.804 recall: 0.788 f1: 0.796 accuracy: 0.974 
training batch:   500, loss: 1.02126, precision: 0.844 recall: 0.864 f1: 0.854 accuracy: 0.979 
training batch:   520, loss: 3.26365, precision: 0.871 recall: 0.818 f1: 0.844 accuracy: 0.954 
training batch:   540, loss: 0.88074, precision: 0.903 recall: 0.875 f1: 0.889 accuracy: 0.983 
training batch:   560, loss: 2.20134, precision: 0.912 recall: 0.825 f1: 0.867 accuracy: 0.958 
training batch:   580, loss: 2.33304, precision: 0.945 recall: 0.867 f1: 0.904 accuracy: 0.972 
training batch:   600, loss: 1.59466, precision: 0.868 recall: 0.807 f1: 0.836 accuracy: 0.978 
training batch:   620, loss: 1.21144, precision: 0.894 recall: 0.857 f1: 0.875 accuracy: 0.979 
training batch:   640, loss: 0.96557, precision: 0.909 recall: 0.857 f1: 0.882 accuracy: 0.992 
training batch:   660, loss: 1.37087, precision: 0.843 recall: 0.827 f1: 0.835 accuracy: 0.979 
training batch:   680, loss: 1.46791, precision: 0.702 recall: 0.750 f1: 0.725 accuracy: 0.972 
training batch:   700, loss: 1.31037, precision: 0.829 recall: 0.829 f1: 0.829 accuracy: 0.982 
training batch:   720, loss: 1.35669, precision: 0.900 recall: 0.818 f1: 0.857 accuracy: 0.984 
start evaluate engines...
label: ORG, precision: 0.790 recall: 0.728 f1: 0.751 accuracy: 0.000 
label: PER, precision: 0.891 recall: 0.848 f1: 0.861 accuracy: 0.000 
label: LOC, precision: 0.806 recall: 0.819 f1: 0.807 accuracy: 0.000 
time consumption:8.36(min), precision: 0.853 recall: 0.818 f1: 0.834 accuracy: 0.978 
saved the new best model with f1: 0.834
epoch:6/300
training batch:    20, loss: 0.99713, precision: 0.851 recall: 0.833 f1: 0.842 accuracy: 0.983 
training batch:    40, loss: 1.73720, precision: 0.837 recall: 0.774 f1: 0.804 accuracy: 0.983 
training batch:    60, loss: 1.28701, precision: 0.854 recall: 0.837 f1: 0.845 accuracy: 0.986 
training batch:    80, loss: 2.49665, precision: 0.880 recall: 0.863 f1: 0.871 accuracy: 0.975 
training batch:   100, loss: 1.04731, precision: 0.867 recall: 0.830 f1: 0.848 accuracy: 0.969 
training batch:   120, loss: 0.85764, precision: 0.906 recall: 0.879 f1: 0.892 accuracy: 0.989 
training batch:   140, loss: 1.78270, precision: 0.870 recall: 0.816 f1: 0.842 accuracy: 0.968 
training batch:   160, loss: 0.47195, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.998 
training batch:   180, loss: 0.93404, precision: 0.865 recall: 0.914 f1: 0.889 accuracy: 0.990 
training batch:   200, loss: 1.33157, precision: 0.845 recall: 0.875 f1: 0.860 accuracy: 0.984 
training batch:   220, loss: 1.25760, precision: 1.000 recall: 0.912 f1: 0.954 accuracy: 0.993 
training batch:   240, loss: 0.73358, precision: 1.000 recall: 0.909 f1: 0.952 accuracy: 0.995 
training batch:   260, loss: 0.98479, precision: 0.943 recall: 0.930 f1: 0.936 accuracy: 0.990 
training batch:   280, loss: 1.21051, precision: 0.860 recall: 0.804 f1: 0.831 accuracy: 0.981 
training batch:   300, loss: 1.58425, precision: 0.902 recall: 0.885 f1: 0.893 accuracy: 0.979 
training batch:   320, loss: 1.56480, precision: 0.816 recall: 0.816 f1: 0.816 accuracy: 0.985 
training batch:   340, loss: 1.40136, precision: 0.833 recall: 0.806 f1: 0.820 accuracy: 0.985 
training batch:   360, loss: 1.34146, precision: 0.919 recall: 0.756 f1: 0.829 accuracy: 0.984 
training batch:   380, loss: 1.43461, precision: 0.774 recall: 0.800 f1: 0.787 accuracy: 0.973 
training batch:   400, loss: 1.14727, precision: 0.881 recall: 0.841 f1: 0.860 accuracy: 0.985 
training batch:   420, loss: 0.56387, precision: 0.818 recall: 0.783 f1: 0.800 accuracy: 0.992 
training batch:   440, loss: 1.68650, precision: 0.842 recall: 0.842 f1: 0.842 accuracy: 0.974 
training batch:   460, loss: 0.90817, precision: 0.905 recall: 0.864 f1: 0.884 accuracy: 0.990 
training batch:   480, loss: 1.35840, precision: 0.851 recall: 0.784 f1: 0.816 accuracy: 0.978 
training batch:   500, loss: 1.99887, precision: 0.891 recall: 0.788 f1: 0.837 accuracy: 0.974 
training batch:   520, loss: 1.07613, precision: 0.765 recall: 0.839 f1: 0.800 accuracy: 0.983 
training batch:   540, loss: 0.71273, precision: 0.964 recall: 1.000 f1: 0.982 accuracy: 0.996 
training batch:   560, loss: 0.89113, precision: 0.880 recall: 0.815 f1: 0.846 accuracy: 0.983 
training batch:   580, loss: 0.98104, precision: 0.837 recall: 0.800 f1: 0.818 accuracy: 0.983 
training batch:   600, loss: 0.94219, precision: 0.857 recall: 0.828 f1: 0.842 accuracy: 0.986 
training batch:   620, loss: 1.36385, precision: 0.902 recall: 0.860 f1: 0.881 accuracy: 0.984 
training batch:   640, loss: 1.74662, precision: 0.851 recall: 0.851 f1: 0.851 accuracy: 0.972 
training batch:   660, loss: 1.20832, precision: 0.915 recall: 0.827 f1: 0.869 accuracy: 0.986 
training batch:   680, loss: 1.48681, precision: 0.821 recall: 0.762 f1: 0.790 accuracy: 0.980 
training batch:   700, loss: 1.11093, precision: 0.875 recall: 0.833 f1: 0.854 accuracy: 0.984 
training batch:   720, loss: 2.88361, precision: 0.843 recall: 0.776 f1: 0.808 accuracy: 0.956 
start evaluate engines...
label: ORG, precision: 0.730 recall: 0.769 f1: 0.740 accuracy: 0.000 
label: PER, precision: 0.893 recall: 0.856 f1: 0.867 accuracy: 0.000 
label: LOC, precision: 0.844 recall: 0.825 f1: 0.830 accuracy: 0.000 
time consumption:8.43(min), precision: 0.848 recall: 0.836 f1: 0.840 accuracy: 0.978 
saved the new best model with f1: 0.840
epoch:7/300
training batch:    20, loss: 0.51939, precision: 0.929 recall: 0.897 f1: 0.912 accuracy: 0.995 
training batch:    40, loss: 0.47336, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.993 
training batch:    60, loss: 0.40645, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.993 
training batch:    80, loss: 1.02489, precision: 0.902 recall: 0.885 f1: 0.893 accuracy: 0.982 
training batch:   100, loss: 0.52697, precision: 0.950 recall: 0.974 f1: 0.962 accuracy: 0.993 
training batch:   120, loss: 1.19160, precision: 0.971 recall: 0.846 f1: 0.904 accuracy: 0.984 
training batch:   140, loss: 0.47218, precision: 0.967 recall: 0.906 f1: 0.935 accuracy: 0.992 
training batch:   160, loss: 0.60664, precision: 0.877 recall: 0.909 f1: 0.893 accuracy: 0.990 
training batch:   180, loss: 0.96256, precision: 0.929 recall: 0.867 f1: 0.897 accuracy: 0.981 
training batch:   200, loss: 1.24438, precision: 0.882 recall: 0.857 f1: 0.870 accuracy: 0.984 
training batch:   220, loss: 0.52616, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.997 
training batch:   240, loss: 1.60445, precision: 0.800 recall: 0.714 f1: 0.755 accuracy: 0.963 
training batch:   260, loss: 0.58801, precision: 0.902 recall: 0.902 f1: 0.902 accuracy: 0.991 
training batch:   280, loss: 1.73686, precision: 0.875 recall: 0.903 f1: 0.889 accuracy: 0.978 
training batch:   300, loss: 0.87071, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.989 
training batch:   320, loss: 1.61697, precision: 0.852 recall: 0.852 f1: 0.852 accuracy: 0.983 
training batch:   340, loss: 0.64611, precision: 0.936 recall: 0.936 f1: 0.936 accuracy: 0.990 
training batch:   360, loss: 0.69768, precision: 0.975 recall: 0.929 f1: 0.951 accuracy: 0.992 
training batch:   380, loss: 0.98430, precision: 0.955 recall: 0.900 f1: 0.926 accuracy: 0.983 
training batch:   400, loss: 0.63831, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.993 
training batch:   420, loss: 1.34929, precision: 0.864 recall: 0.844 f1: 0.854 accuracy: 0.985 
training batch:   440, loss: 1.22438, precision: 0.949 recall: 0.862 f1: 0.903 accuracy: 0.988 
training batch:   460, loss: 1.88741, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.970 
training batch:   480, loss: 1.67675, precision: 0.912 recall: 0.886 f1: 0.899 accuracy: 0.976 
training batch:   500, loss: 1.11704, precision: 0.918 recall: 0.818 f1: 0.865 accuracy: 0.978 
training batch:   520, loss: 1.09894, precision: 0.935 recall: 0.784 f1: 0.853 accuracy: 0.986 
training batch:   540, loss: 1.26766, precision: 0.922 recall: 0.922 f1: 0.922 accuracy: 0.990 
training batch:   560, loss: 1.44921, precision: 0.878 recall: 0.915 f1: 0.896 accuracy: 0.978 
training batch:   580, loss: 1.31274, precision: 0.885 recall: 0.902 f1: 0.893 accuracy: 0.979 
training batch:   600, loss: 0.43017, precision: 0.923 recall: 0.857 f1: 0.889 accuracy: 0.989 
training batch:   620, loss: 0.92404, precision: 0.898 recall: 0.880 f1: 0.889 accuracy: 0.983 
training batch:   640, loss: 1.15390, precision: 0.826 recall: 0.884 f1: 0.854 accuracy: 0.973 
training batch:   660, loss: 1.24286, precision: 0.872 recall: 0.872 f1: 0.872 accuracy: 0.985 
training batch:   680, loss: 1.46854, precision: 0.905 recall: 0.919 f1: 0.912 accuracy: 0.987 
training batch:   700, loss: 1.40751, precision: 0.937 recall: 0.881 f1: 0.908 accuracy: 0.983 
training batch:   720, loss: 0.93001, precision: 0.894 recall: 0.894 f1: 0.894 accuracy: 0.988 
start evaluate engines...
label: ORG, precision: 0.772 recall: 0.744 f1: 0.751 accuracy: 0.000 
label: PER, precision: 0.897 recall: 0.868 f1: 0.874 accuracy: 0.000 
label: LOC, precision: 0.847 recall: 0.837 f1: 0.836 accuracy: 0.000 
time consumption:8.31(min), precision: 0.865 recall: 0.835 f1: 0.849 accuracy: 0.979 
saved the new best model with f1: 0.849
epoch:8/300
training batch:    20, loss: 1.03608, precision: 0.861 recall: 0.816 f1: 0.838 accuracy: 0.974 
training batch:    40, loss: 1.18783, precision: 0.880 recall: 0.846 f1: 0.863 accuracy: 0.983 
training batch:    60, loss: 0.68016, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.992 
training batch:    80, loss: 1.04509, precision: 0.932 recall: 0.837 f1: 0.882 accuracy: 0.983 
training batch:   100, loss: 0.60810, precision: 0.935 recall: 0.956 f1: 0.945 accuracy: 0.996 
training batch:   120, loss: 0.68797, precision: 0.966 recall: 0.934 f1: 0.950 accuracy: 0.982 
training batch:   140, loss: 0.57215, precision: 0.977 recall: 0.915 f1: 0.945 accuracy: 0.994 
training batch:   160, loss: 0.40566, precision: 0.957 recall: 0.938 f1: 0.947 accuracy: 0.996 
training batch:   180, loss: 1.73283, precision: 0.915 recall: 0.878 f1: 0.897 accuracy: 0.974 
training batch:   200, loss: 1.02061, precision: 0.853 recall: 0.806 f1: 0.829 accuracy: 0.988 
training batch:   220, loss: 0.59610, precision: 0.842 recall: 0.889 f1: 0.865 accuracy: 0.988 
training batch:   240, loss: 0.85763, precision: 0.915 recall: 0.964 f1: 0.939 accuracy: 0.988 
training batch:   260, loss: 1.19140, precision: 0.948 recall: 0.917 f1: 0.932 accuracy: 0.979 
training batch:   280, loss: 0.74392, precision: 0.938 recall: 0.789 f1: 0.857 accuracy: 0.976 
training batch:   300, loss: 0.97655, precision: 0.927 recall: 0.905 f1: 0.916 accuracy: 0.981 
training batch:   320, loss: 1.75885, precision: 0.855 recall: 0.757 f1: 0.803 accuracy: 0.978 
training batch:   340, loss: 0.77164, precision: 0.919 recall: 0.919 f1: 0.919 accuracy: 0.992 
training batch:   360, loss: 0.53243, precision: 0.980 recall: 0.925 f1: 0.951 accuracy: 0.988 
training batch:   380, loss: 0.31751, precision: 0.944 recall: 1.000 f1: 0.971 accuracy: 0.993 
training batch:   400, loss: 0.75594, precision: 0.958 recall: 0.868 f1: 0.911 accuracy: 0.991 
training batch:   420, loss: 1.24285, precision: 0.886 recall: 0.848 f1: 0.867 accuracy: 0.989 
training batch:   440, loss: 0.77138, precision: 0.931 recall: 0.947 f1: 0.939 accuracy: 0.987 
training batch:   460, loss: 0.76859, precision: 0.936 recall: 0.936 f1: 0.936 accuracy: 0.992 
training batch:   480, loss: 1.20545, precision: 0.857 recall: 0.857 f1: 0.857 accuracy: 0.982 
training batch:   500, loss: 0.52932, precision: 0.886 recall: 0.886 f1: 0.886 accuracy: 0.992 
training batch:   520, loss: 0.66341, precision: 0.957 recall: 0.882 f1: 0.918 accuracy: 0.986 
training batch:   540, loss: 0.79689, precision: 0.976 recall: 0.976 f1: 0.976 accuracy: 0.995 
training batch:   560, loss: 0.87611, precision: 0.907 recall: 0.907 f1: 0.907 accuracy: 0.984 
training batch:   580, loss: 1.38347, precision: 0.933 recall: 0.875 f1: 0.903 accuracy: 0.980 
training batch:   600, loss: 0.71826, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.985 
training batch:   620, loss: 0.76655, precision: 0.912 recall: 0.945 f1: 0.929 accuracy: 0.987 
training batch:   640, loss: 0.62057, precision: 0.893 recall: 0.806 f1: 0.847 accuracy: 0.992 
training batch:   660, loss: 1.03395, precision: 0.846 recall: 0.846 f1: 0.846 accuracy: 0.967 
training batch:   680, loss: 1.07031, precision: 0.882 recall: 0.833 f1: 0.857 accuracy: 0.992 
training batch:   700, loss: 0.88841, precision: 0.865 recall: 0.842 f1: 0.853 accuracy: 0.982 
training batch:   720, loss: 0.51045, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.991 
start evaluate engines...
label: ORG, precision: 0.769 recall: 0.772 f1: 0.763 accuracy: 0.000 
label: PER, precision: 0.892 recall: 0.866 f1: 0.871 accuracy: 0.000 
label: LOC, precision: 0.843 recall: 0.856 f1: 0.844 accuracy: 0.000 
time consumption:8.49(min), precision: 0.860 recall: 0.850 f1: 0.853 accuracy: 0.979 
saved the new best model with f1: 0.853
epoch:9/300
training batch:    20, loss: 0.67867, precision: 0.959 recall: 0.922 f1: 0.940 accuracy: 0.995 
training batch:    40, loss: 0.44671, precision: 0.960 recall: 0.941 f1: 0.950 accuracy: 0.992 
training batch:    60, loss: 0.62231, precision: 0.893 recall: 0.909 f1: 0.901 accuracy: 0.994 
training batch:    80, loss: 0.54139, precision: 0.915 recall: 0.947 f1: 0.931 accuracy: 0.992 
training batch:   100, loss: 0.46389, precision: 0.956 recall: 0.935 f1: 0.945 accuracy: 0.993 
training batch:   120, loss: 0.59932, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.993 
training batch:   140, loss: 0.28212, precision: 0.974 recall: 0.925 f1: 0.949 accuracy: 0.997 
training batch:   160, loss: 1.08060, precision: 0.931 recall: 0.885 f1: 0.908 accuracy: 0.985 
training batch:   180, loss: 0.77099, precision: 0.981 recall: 0.945 f1: 0.963 accuracy: 0.987 
training batch:   200, loss: 0.55261, precision: 0.925 recall: 0.961 f1: 0.942 accuracy: 0.993 
training batch:   220, loss: 0.31811, precision: 0.974 recall: 0.974 f1: 0.974 accuracy: 0.998 
training batch:   240, loss: 0.72697, precision: 0.886 recall: 0.867 f1: 0.876 accuracy: 0.987 
training batch:   260, loss: 0.53372, precision: 0.833 recall: 0.800 f1: 0.816 accuracy: 0.993 
training batch:   280, loss: 0.90323, precision: 0.906 recall: 0.889 f1: 0.897 accuracy: 0.990 
training batch:   300, loss: 0.97487, precision: 0.887 recall: 0.870 f1: 0.879 accuracy: 0.980 
training batch:   320, loss: 0.68861, precision: 0.900 recall: 0.865 f1: 0.882 accuracy: 0.989 
training batch:   340, loss: 0.78252, precision: 0.929 recall: 0.945 f1: 0.937 accuracy: 0.991 
training batch:   360, loss: 0.88009, precision: 0.947 recall: 0.911 f1: 0.929 accuracy: 0.990 
training batch:   380, loss: 0.68625, precision: 0.865 recall: 0.865 f1: 0.865 accuracy: 0.992 
training batch:   400, loss: 0.48947, precision: 0.968 recall: 0.909 f1: 0.937 accuracy: 0.995 
training batch:   420, loss: 0.83596, precision: 0.918 recall: 0.882 f1: 0.900 accuracy: 0.987 
training batch:   440, loss: 0.62667, precision: 0.882 recall: 0.957 f1: 0.918 accuracy: 0.988 
training batch:   460, loss: 1.11440, precision: 0.946 recall: 0.897 f1: 0.921 accuracy: 0.982 
training batch:   480, loss: 0.71182, precision: 0.889 recall: 0.865 f1: 0.877 accuracy: 0.991 
training batch:   500, loss: 0.67280, precision: 0.959 recall: 0.959 f1: 0.959 accuracy: 0.994 
training batch:   520, loss: 0.58179, precision: 0.938 recall: 0.957 f1: 0.947 accuracy: 0.994 
training batch:   540, loss: 0.51040, precision: 0.919 recall: 0.944 f1: 0.932 accuracy: 0.987 
training batch:   560, loss: 0.81164, precision: 0.921 recall: 0.854 f1: 0.886 accuracy: 0.992 
training batch:   580, loss: 0.34381, precision: 1.000 recall: 0.933 f1: 0.966 accuracy: 0.995 
training batch:   600, loss: 0.51491, precision: 0.980 recall: 0.943 f1: 0.962 accuracy: 0.993 
training batch:   620, loss: 1.78453, precision: 0.854 recall: 0.778 f1: 0.814 accuracy: 0.973 
training batch:   640, loss: 1.02960, precision: 0.862 recall: 0.926 f1: 0.893 accuracy: 0.993 
training batch:   660, loss: 1.33549, precision: 0.905 recall: 0.877 f1: 0.891 accuracy: 0.984 
training batch:   680, loss: 0.97399, precision: 0.898 recall: 0.869 f1: 0.883 accuracy: 0.982 
training batch:   700, loss: 0.54822, precision: 0.882 recall: 0.938 f1: 0.909 accuracy: 0.989 
training batch:   720, loss: 0.40193, precision: 0.973 recall: 0.947 f1: 0.960 accuracy: 0.998 
start evaluate engines...
label: ORG, precision: 0.729 recall: 0.792 f1: 0.752 accuracy: 0.000 
label: PER, precision: 0.908 recall: 0.857 f1: 0.875 accuracy: 0.000 
label: LOC, precision: 0.862 recall: 0.839 f1: 0.845 accuracy: 0.000 
time consumption:8.31(min), precision: 0.857 recall: 0.851 f1: 0.853 accuracy: 0.979 
epoch:10/300
training batch:    20, loss: 0.78986, precision: 0.972 recall: 0.897 f1: 0.933 accuracy: 0.988 
training batch:    40, loss: 0.65855, precision: 0.923 recall: 0.923 f1: 0.923 accuracy: 0.985 
training batch:    60, loss: 0.45382, precision: 0.930 recall: 0.946 f1: 0.938 accuracy: 0.985 
training batch:    80, loss: 0.52850, precision: 0.971 recall: 0.919 f1: 0.944 accuracy: 0.992 
training batch:   100, loss: 0.57498, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.989 
training batch:   120, loss: 0.79326, precision: 0.907 recall: 0.867 f1: 0.886 accuracy: 0.988 
training batch:   140, loss: 0.61873, precision: 0.947 recall: 0.947 f1: 0.947 accuracy: 0.999 
training batch:   160, loss: 0.66443, precision: 0.942 recall: 0.942 f1: 0.942 accuracy: 0.991 
training batch:   180, loss: 0.42994, precision: 0.964 recall: 0.981 f1: 0.972 accuracy: 0.996 
training batch:   200, loss: 0.44604, precision: 0.936 recall: 1.000 f1: 0.967 accuracy: 0.989 
training batch:   220, loss: 0.51262, precision: 0.944 recall: 0.944 f1: 0.944 accuracy: 0.995 
training batch:   240, loss: 0.72903, precision: 0.948 recall: 0.887 f1: 0.917 accuracy: 0.981 
training batch:   260, loss: 0.55311, precision: 0.932 recall: 0.932 f1: 0.932 accuracy: 0.990 
training batch:   280, loss: 0.38130, precision: 0.961 recall: 0.980 f1: 0.970 accuracy: 0.995 
training batch:   300, loss: 1.09461, precision: 0.881 recall: 0.881 f1: 0.881 accuracy: 0.983 
training batch:   320, loss: 0.22425, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.996 
training batch:   340, loss: 0.75730, precision: 0.885 recall: 0.885 f1: 0.885 accuracy: 0.985 
training batch:   360, loss: 0.62496, precision: 0.919 recall: 0.950 f1: 0.934 accuracy: 0.992 
training batch:   380, loss: 0.82353, precision: 0.826 recall: 0.864 f1: 0.844 accuracy: 0.983 
training batch:   400, loss: 0.56784, precision: 0.878 recall: 0.923 f1: 0.900 accuracy: 0.993 
training batch:   420, loss: 0.51199, precision: 0.897 recall: 0.972 f1: 0.933 accuracy: 0.991 
training batch:   440, loss: 0.34165, precision: 1.000 recall: 0.960 f1: 0.980 accuracy: 0.992 
training batch:   460, loss: 0.23915, precision: 1.000 recall: 0.977 f1: 0.988 accuracy: 0.998 
training batch:   480, loss: 1.00588, precision: 0.855 recall: 0.855 f1: 0.855 accuracy: 0.978 
training batch:   500, loss: 0.24201, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.993 
training batch:   520, loss: 0.57019, precision: 0.946 recall: 0.946 f1: 0.946 accuracy: 0.994 
training batch:   540, loss: 0.64505, precision: 0.952 recall: 0.930 f1: 0.941 accuracy: 0.992 
training batch:   560, loss: 0.60997, precision: 0.962 recall: 0.911 f1: 0.936 accuracy: 0.997 
training batch:   580, loss: 0.98831, precision: 0.881 recall: 0.881 f1: 0.881 accuracy: 0.985 
training batch:   600, loss: 0.75434, precision: 0.911 recall: 0.872 f1: 0.891 accuracy: 0.991 
training batch:   620, loss: 0.54603, precision: 0.960 recall: 0.923 f1: 0.941 accuracy: 0.995 
training batch:   640, loss: 0.56211, precision: 0.964 recall: 0.946 f1: 0.955 accuracy: 0.990 
training batch:   660, loss: 0.50051, precision: 1.000 recall: 0.938 f1: 0.968 accuracy: 0.998 
training batch:   680, loss: 1.16829, precision: 0.896 recall: 0.896 f1: 0.896 accuracy: 0.980 
training batch:   700, loss: 0.59560, precision: 0.952 recall: 0.941 f1: 0.947 accuracy: 0.989 
training batch:   720, loss: 0.62953, precision: 0.979 recall: 0.940 f1: 0.959 accuracy: 0.995 
start evaluate engines...
label: ORG, precision: 0.817 recall: 0.756 f1: 0.777 accuracy: 0.000 
label: PER, precision: 0.883 recall: 0.881 f1: 0.876 accuracy: 0.000 
label: LOC, precision: 0.837 recall: 0.871 f1: 0.849 accuracy: 0.000 
time consumption:8.33(min), precision: 0.871 recall: 0.857 f1: 0.863 accuracy: 0.981 
saved the new best model with f1: 0.863
epoch:11/300
training batch:    20, loss: 0.29189, precision: 0.969 recall: 0.969 f1: 0.969 accuracy: 0.993 
training batch:    40, loss: 0.56680, precision: 0.897 recall: 0.921 f1: 0.909 accuracy: 0.994 
training batch:    60, loss: 0.20875, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:    80, loss: 0.27619, precision: 0.965 recall: 0.948 f1: 0.957 accuracy: 0.996 
training batch:   100, loss: 0.31965, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.997 
training batch:   120, loss: 0.25417, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.995 
training batch:   140, loss: 0.38058, precision: 0.944 recall: 0.981 f1: 0.962 accuracy: 0.990 
training batch:   160, loss: 0.33383, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.995 
training batch:   180, loss: 0.25118, precision: 0.970 recall: 0.970 f1: 0.970 accuracy: 0.995 
training batch:   200, loss: 0.28623, precision: 0.982 recall: 0.948 f1: 0.965 accuracy: 0.999 
training batch:   220, loss: 0.58696, precision: 0.960 recall: 0.906 f1: 0.932 accuracy: 0.992 
training batch:   240, loss: 0.50369, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.989 
training batch:   260, loss: 0.42092, precision: 0.979 recall: 0.979 f1: 0.979 accuracy: 0.993 
training batch:   280, loss: 0.30573, precision: 0.959 recall: 0.940 f1: 0.949 accuracy: 0.997 
training batch:   300, loss: 0.77234, precision: 0.886 recall: 0.848 f1: 0.867 accuracy: 0.987 
training batch:   320, loss: 0.52243, precision: 0.971 recall: 0.944 f1: 0.957 accuracy: 0.990 
training batch:   340, loss: 0.34687, precision: 0.978 recall: 0.957 f1: 0.967 accuracy: 0.995 
training batch:   360, loss: 0.56279, precision: 0.978 recall: 0.936 f1: 0.957 accuracy: 0.993 
training batch:   380, loss: 0.64229, precision: 0.911 recall: 0.895 f1: 0.903 accuracy: 0.991 
training batch:   400, loss: 0.51435, precision: 0.939 recall: 0.939 f1: 0.939 accuracy: 0.991 
training batch:   420, loss: 0.59627, precision: 0.951 recall: 0.929 f1: 0.940 accuracy: 0.988 
training batch:   440, loss: 0.74619, precision: 0.926 recall: 0.893 f1: 0.909 accuracy: 0.988 
training batch:   460, loss: 0.32787, precision: 1.000 recall: 0.927 f1: 0.962 accuracy: 0.993 
training batch:   480, loss: 0.58557, precision: 0.974 recall: 0.927 f1: 0.950 accuracy: 0.996 
training batch:   500, loss: 0.92703, precision: 0.979 recall: 0.920 f1: 0.948 accuracy: 0.991 
training batch:   520, loss: 0.43606, precision: 1.000 recall: 0.950 f1: 0.974 accuracy: 0.997 
training batch:   540, loss: 1.33689, precision: 0.902 recall: 0.822 f1: 0.860 accuracy: 0.989 
training batch:   560, loss: 0.92255, precision: 0.966 recall: 0.935 f1: 0.950 accuracy: 0.995 
training batch:   580, loss: 0.26274, precision: 0.978 recall: 1.000 f1: 0.989 accuracy: 0.997 
training batch:   600, loss: 0.23542, precision: 0.977 recall: 1.000 f1: 0.989 accuracy: 0.999 
training batch:   620, loss: 0.34558, precision: 0.964 recall: 0.982 f1: 0.973 accuracy: 0.992 
training batch:   640, loss: 0.59676, precision: 0.949 recall: 0.902 f1: 0.925 accuracy: 0.989 
training batch:   660, loss: 0.71192, precision: 0.959 recall: 0.922 f1: 0.940 accuracy: 0.990 
training batch:   680, loss: 0.81863, precision: 0.844 recall: 0.818 f1: 0.831 accuracy: 0.974 
training batch:   700, loss: 0.22297, precision: 0.943 recall: 0.971 f1: 0.957 accuracy: 0.998 
training batch:   720, loss: 0.88314, precision: 0.933 recall: 0.918 f1: 0.926 accuracy: 0.992 
start evaluate engines...
label: ORG, precision: 0.792 recall: 0.752 f1: 0.764 accuracy: 0.000 
label: PER, precision: 0.897 recall: 0.882 f1: 0.883 accuracy: 0.000 
label: LOC, precision: 0.833 recall: 0.876 f1: 0.849 accuracy: 0.000 
time consumption:8.35(min), precision: 0.862 recall: 0.858 f1: 0.859 accuracy: 0.980 
epoch:12/300
training batch:    20, loss: 0.29477, precision: 0.923 recall: 0.947 f1: 0.935 accuracy: 0.990 
training batch:    40, loss: 0.59215, precision: 0.951 recall: 0.935 f1: 0.943 accuracy: 0.992 
training batch:    60, loss: 0.45152, precision: 0.941 recall: 0.941 f1: 0.941 accuracy: 0.993 
training batch:    80, loss: 0.15097, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   100, loss: 0.36659, precision: 0.951 recall: 0.951 f1: 0.951 accuracy: 0.998 
training batch:   120, loss: 0.24360, precision: 1.000 recall: 0.941 f1: 0.970 accuracy: 0.998 
training batch:   140, loss: 0.30116, precision: 0.925 recall: 0.949 f1: 0.937 accuracy: 0.996 
training batch:   160, loss: 0.56192, precision: 0.983 recall: 0.983 f1: 0.983 accuracy: 0.995 
training batch:   180, loss: 0.28043, precision: 0.952 recall: 1.000 f1: 0.976 accuracy: 0.996 
training batch:   200, loss: 0.57807, precision: 0.945 recall: 0.945 f1: 0.945 accuracy: 0.992 
training batch:   220, loss: 0.49499, precision: 0.944 recall: 0.895 f1: 0.919 accuracy: 0.994 
training batch:   240, loss: 0.25314, precision: 0.980 recall: 1.000 f1: 0.990 accuracy: 0.998 
training batch:   260, loss: 0.22764, precision: 0.936 recall: 0.978 f1: 0.957 accuracy: 0.996 
training batch:   280, loss: 0.63148, precision: 0.942 recall: 0.961 f1: 0.951 accuracy: 0.991 
training batch:   300, loss: 0.41828, precision: 0.956 recall: 0.896 f1: 0.925 accuracy: 0.992 
training batch:   320, loss: 0.36231, precision: 0.840 recall: 0.913 f1: 0.875 accuracy: 0.994 
training batch:   340, loss: 0.43762, precision: 1.000 recall: 0.981 f1: 0.990 accuracy: 0.997 
training batch:   360, loss: 0.50443, precision: 0.980 recall: 0.961 f1: 0.970 accuracy: 0.991 
training batch:   380, loss: 1.09193, precision: 0.922 recall: 0.904 f1: 0.913 accuracy: 0.988 
training batch:   400, loss: 0.15045, precision: 0.983 recall: 1.000 f1: 0.991 accuracy: 0.996 
training batch:   420, loss: 0.89621, precision: 0.949 recall: 0.860 f1: 0.902 accuracy: 0.988 
training batch:   440, loss: 0.42796, precision: 0.886 recall: 0.939 f1: 0.912 accuracy: 0.987 
training batch:   460, loss: 0.37970, precision: 0.967 recall: 0.967 f1: 0.967 accuracy: 0.994 
training batch:   480, loss: 0.19952, precision: 0.931 recall: 0.964 f1: 0.947 accuracy: 0.996 
training batch:   500, loss: 0.37973, precision: 0.948 recall: 0.982 f1: 0.965 accuracy: 0.994 
training batch:   520, loss: 0.52044, precision: 0.895 recall: 0.879 f1: 0.887 accuracy: 0.983 
training batch:   540, loss: 0.77974, precision: 0.863 recall: 0.880 f1: 0.871 accuracy: 0.986 
training batch:   560, loss: 0.28817, precision: 0.920 recall: 0.852 f1: 0.885 accuracy: 0.996 
training batch:   580, loss: 0.29664, precision: 0.971 recall: 0.971 f1: 0.971 accuracy: 0.994 
training batch:   600, loss: 0.48270, precision: 0.959 recall: 0.973 f1: 0.966 accuracy: 0.991 
training batch:   620, loss: 0.56802, precision: 0.984 recall: 0.955 f1: 0.969 accuracy: 0.993 
training batch:   640, loss: 0.30520, precision: 0.942 recall: 0.891 f1: 0.916 accuracy: 0.994 
training batch:   660, loss: 0.43109, precision: 0.976 recall: 0.953 f1: 0.965 accuracy: 0.994 
training batch:   680, loss: 0.55240, precision: 0.965 recall: 0.965 f1: 0.965 accuracy: 0.994 
training batch:   700, loss: 0.10056, precision: 1.000 recall: 1.000 f1: 1.000 accuracy: 1.000 
training batch:   720, loss: 0.17377, precision: 0.925 recall: 0.902 f1: 0.914 accuracy: 0.997 
start evaluate engines...
